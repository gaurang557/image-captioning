"""Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AN2daK8MrIrj7gDF5cZ4AYNlunHeV2IH
"""

import pickle
from keras.preprocessing import image
from keras.models import *
import numpy as np
import keras
from keras.models import Model
from keras.layers import *
import matplotlib.pyplot as plt
from keras.applications.resnet50 import ResNet50,preprocess_input
from nltk.tokenize import word_tokenize
import re
import collections
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical

with open('drive/MyDrive/flickr/captions.txt',encoding='utf8') as f:
    s=f.readlines()
img_cap={}
for i in s:
    i=i.lower()
    li=i.split('.jpg,')
    if img_cap.get(li[0]+'.jpg') is None:
        img_cap[li[0]+'.jpg']=[]
    caption='startseq '+''.join(li[1][:-2])
    caption+=' endseq'
    img_cap[li[0]+'.jpg'].append(caption)
tot_words=[]
for i in img_cap.keys():
    [tot_words.append(k) for d in img_cap[i] for k in d.split()]
x=collections.Counter(tot_words)
x=dict(x)
fv=x.items()
fin_vocab=[d for d in fv if d[1]>10]
fv=[a[0] for a in fin_vocab]
fv=[a for a in fv if len(a)>1]

word2idx['startseq']

mod=ResNet50(weights='imagenet',input_shape=(224,224,3))
# model.summary()
model_res=Model(mod.input,mod.layers[-2].output)
import os
def get(path):
    if not os.path.exists(path):
        return 0
    img=image.load_img(path,target_size=(224,224,3))
    img=image.img_to_array(img)
    img=np.expand_dims(img,axis=0)
    img=preprocess_input(img)
    img=model_res.predict(img)
    img=img.reshape((-1,))
    return img
word2idx={}
idx2word = {}
for i,j in enumerate(fv):
    word2idx[j]=i+1
    idx2word[i+1]=j

with open('drive/MyDrive/flickr/encoded_imgs.pickle',"rb") as f:
  encoded_imgs=pickle.load(f)

def data_gen(batch_size,img_cap,encoded_imgs,word2idx):
    p,x,y=[],[],[]
    n=0
    for i,j in img_cap.items():
        n+=1
        pic=encoded_imgs[i]
        for k in j:
            seq=[word2idx[c] for c in k.split() if c in word2idx.keys()]
            
            for l in range(1,len(seq)):
                x1=seq[0:l]
                y1=seq[l]
                x1=pad_sequences([x1],maxlen=maxlen,value=0,padding='post')[0]
                y1=to_categorical([y1],num_classes=vocab_size)[0]
                p.append(pic)
                x.append(x1)
                y.append(y1)
        if n==batch_size:
            yield ([np.array(p),np.array(x)],np.array(y))
            p,x,y=[],[],[];n=0

vocab_size=len(fv)
epochs=20
batch_size=3

glove_embedding={}
with open('./drive/MyDrive/glove/glove.txt',encoding='utf8') as f:
    w=f.readlines()
    for i in w:
        li=i.split()
        glove_embedding[li[0]]=np.array(li[1:])
matrix=np.zeros((vocab_size,50))
for word,idx in word2idx.items():
    if glove_embedding.get(word) is None:
        continue
    else:
        matrix[idx-1]=glove_embedding[word]

img_cap.values()

maxlen=max([len(low.split()) for items in img_cap.values() for low in items])
print(maxlen)

img1=Input(shape=(2048,))
img2=Dropout(0.3)(img1)
img3=Dense(256,activation='relu')(img2)

cap1=Input(shape=(39,))
cap2=Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(cap1)
ds=Dropout(0.3)(cap2)
cap3=LSTM(256)(ds)

decoder1=add([img3,cap3])
decoder2=Dense(256,activation='relu')(decoder1)
dec3=Dense(1923,activation='softmax')(decoder2)

model=Model(inputs=[img1,cap1],outputs=dec3)
model.layers[2].trainable=False
model.layers[2].set_weights([matrix])
model.compile(loss='categorical_crossentropy',optimizer='adam')
model.summary()

for i in range(20,epochs+5):
    generator=data_gen(batch_size,img_cap,encoded_imgs,word2idx)
    model.fit_generator(generator,epochs=1,steps_per_epoch=1819//3 ,verbose=1)
    model.save('drive/MyDrive/new_image_captioning_models/colab model {}.h5'.format(i))

def predict(model,img):
    s='startseq';seq=""
    img=get(img).reshape(1,2048)
    while True:        
        cap=[word2idx[c] for c in s.split() if c in word2idx.keys()]
        cap=pad_sequences([cap],maxlen=39,value=0,padding='post')[0].reshape(1,39)        
        res=model.predict([img,cap])
        res=np.argmax(res)
        s+=' '+idx2word[res]
        print(idx2word[res],end=" ")
        if idx2word[res]=='endseq':
            return seq
        seq+=idx2word[res]+" "

predict(model,"drive/MyDrive/flickr/Images/47870024_73a4481f7d.jpg")

model.save_weights("drive/MyDrive/modelgaurang.hdf5")

model.summary()